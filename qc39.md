# Problem Set 2: Cooperative AI and the Future of Mechanism Design

Author: Qitong Cao :tent:

Class of 2022, Applied Mathematics, Duke Kunshan Univesity

Disclaimer: Submissions to Problem Set 2 for COMPSCI/ECON 206 Computational Microeconomics, 2022 Spring Term (Seven Week - Second) instructed by Prof. Luyao Zhang at Duke Kunshan University.

---
### **RQ1: What is cooperative AI? What do you see as the potential that computer science and economics can jointly contribute to advance cooperative AI?**


Cooperative AI is designed to assist humanity in dealing with fundamental problems of cooperation via re-conceiving AI as deeply social [(Dafoe et al. 2021)](https://doi.org/10.1038/d41586-021-01170-0.). Cooperative AI, shedding light on the intersection between game theory and artificial intelligence, holds the potential to navigate social dilemmas well. It provides an environment where artificial learning agents in addition to humans can participate actively with increasing interactions in a variety of complex settings such as social dilemmas. The cooperative intelligence should meet four requirements: 
 - Understanding: the capability to analyze circumstances 
 - Communication: the capability to share the information 
 - Commitment: the capability to stick to promises for cooperation 
 - Norms and institutions: the social infrastructure which reinforces the previous three capabilities.
 

Computer science and economics can jointly accelerate cooperative AI research to achieve central goals: the advanced technology and innovative algorithm in computer science, combining the developing individual behavioral microeconomics and game theory in economics, will contribute to *“building machine agents with the capabilities for cooperation”*; the existing real practices in creating and solving games along with the continuous improvement of software and hardware in computer science show the potential to build *“tools to foster cooperation in populations of both machine and human agents".* [(Dafoe et al. 2020)](https://arxiv.org/pdf/2012.08630.pdf). Additionally, previous theoretical foundations in game theory and social dilemma have offered a solid basis for the research while the multi-agent system in computer science is making the future interaction between machines and human beings possible. 

---
### **RQ2: Besides the desirable outcomes of cooperation, what other desirable outcomes the mechanism design theory aims at achieving?**

Mechanism design proposes the assumption that participated agents will behave to maximize their payoffs as a strategic version of social choice theory under different situations, indicating the wide application of mechanism designs. 

![Mechanism Design](./Mechanism-Design-or-Reverse-Game-Theory.png)

Mechanism design’s computational applications study mechanisms that contain a computational ingredient or mechanisms applied to computational domains such as computer networks [(Haris 2010)](https://doi.org/10.1145/1753171.1753181). Besides, stepping out of the virtual world, mechanism design also has highly influential applications in real practices. For instance, the theory marks a breakthrough in the modern economic analysis of institutions and markets, creating a lasting influence on the design of economic policies. According to the mechanism theory, we can deduct that when markets or market-based institutions are likely to yield desirable outcomes, and when other institutions will be better at achieving the desired goals. When markets fail, mechanism design theory tells us how to design such alternative institutions. Besides, mechanism design has also revolutionized the field of regulation. In work with David Baron, Myerson was the first to question the conventional assumption that regulators “know everything” and to use mechanism design to derive optimal regulatory schemes to minimize the cost of provision of public services. In real life, mechanism design is frequently adopted in auctions, which both [Maskin and Myerson]( https://www.nobelprize.org/prizes/economic-sciences/2007/summary/), have heavily contributed to via leading a role to extend the revelation principle to Bayesian incentive compatible mechanisms.[^1] Additionally, mechanism design theory can be used in nature reserves as well, telling us how to design environmentally sustainable fishing and hunting schemes. 
[^1]:The Sveriges Riksbank Prize in Economic Sciences in Memory of Alfred Nobel 2007 was awarded jointly to Leonid Hurwicz, Eric S. Maskin and Roger B. Myerson "for having laid the foundations of mechanism design theory."

---
### **RQ3: What are the limitations of the current mechanism design theory in achieving desirable outcomes? What new challenging are we facing in a new era with more and more human and AI interactions?**

The divergence of impossibility theorems defines the combinations of features that no system with fully rational agents can attain in specific sorts of settings. A novel class of problems that are approximable in the absence of strategic constraints and have an optimal incentive-compatible solution when no computational constraints are enforced; for this class of problems, there is no algorithm with a reasonable approximation ratio that is both computationally feasible and incentive-compatible under standard computational assumptions. This resolves the major open challenge in algorithmic mechanism design, which has been centered on demonstrating the difficulties of polynomial-time incentive compatibility since its beginnings. The *[Gibbard and Satterthwaite impossibility theorem](https://doi.org/10.1142/9789814525053_0017)* states that it is impossible to implement a good social choice function in dominant strategies given a sufficiently rich class of agent preferences. *Green and Laffont and Hurwicz's related impossibility* result proves the impossibility of efficiency and budget balance with dominant strategy execution, even in quasi-linear situations.

The capacity to present all alternative solutions from which a designer or even a user may pick the one deemed appropriate for the requirement beneath the solution has been characterized as the difficulty of Mechanism Design. As part of the design challenge, analytical methodologies are also requested to produce adequate new assessments of the new projected performance. The systems in real-world practices are usually deployed in messy, ambiguous, real-world environments, the pursuit of what appear to be natural objective functions can often lead us wrong. Maximizing the proportion of properly identified cases in deployed machine learning systems may result in systems that discriminate against specific subsets of the population [(Conitzer, 2019)](https://doi.org/10.1609/aaai.v33i01.33019755).

---
### **RQ4: What new challenging are we facing in a new era with more and more humans and AI interactions?**

The computational mechanism makes it difficult or impossible for artificial intelligence to simulate human advanced cognitive ability, which leads to the bottleneck effect of the relevant technological development as it does not apply to <mark>all real-world circumstances</mark>, such as marriage, inheritance division, and team contribution. In most cases, it creates difficulties to get AI to work efficiently since they have specified identities, beliefs, and preferences [(Conitzer, 2019)](https://doi.org/10.1609/aaai.v33i01.33019755). As [Dafoe et al (2021)]( https://doi.org/10.1038/d41586-021-01170-0) pointed out, a perceived lack of fairness in resource allocation in a social group may cause the breakdown of the cooperative structures. Furthermore, the AI system lacks sufficient consideration of human interference and control. For instance, to achieve the ideal outcome in mechanism design, the individual agents are supposed to truthfully share or communicate the relevant preference information [(Dafoe et al. 2012)]( https://doi.org/10.1038/d41586-021-01170-0). However, the human-AI system meets the challenge when the self-interest of agents leads them to misreport or miscommunicate the existing information.

Besides, just as [Dafoe et al. (2012)]( https://doi.org/10.1038/d41586-021-01170-0) promoted, there remain numerous important outstanding problems that require further study. Another challenge turns out to be the lack of mature human-AI cooperation theory based on the relevant application of social choice and mechanism design, a corresponding method, and a machine cognitive framework. In terms of human-AI interaction, the lack of mature human-machine awareness sharing, human-machine mutual trust construction, human-machine psychological model, and human-machine decision-making sharing theory are all setting obstacles o the journey of increasing human-AI interactions.

Additionally, when it comes to product service and consumer experience, the challenge of the *AI "black box"* effect occurs. The users’ decision-making process might be negatively influenced since they can not understand the AI decision-making system, which will block the promotion of AI products. In real practices, the lack of end-user participation makes the psychological explanation theory not applied - in most cases, AI’s decision can be explained but end users can not understand it, which leads to their non-understandable decision. 

---
### **RQ5: Based on your interest and your advantage in skills, how do you plan to contribute to overcoming the limitations of the current mechanism design theory in achieving desirable outcomes and making this world a better place?**

Due to the immature machine learning training and testing methods, AI system is still struggling with problems such as potentially biased system outputs, unexpected machine behavior, and unique machine behavior evolution. Machine learning's lack of user participation leads to complex machine behavior in social interactions and complex interactions between multiple AI agents. To improve the situation, I might contribute to developing human-centered machine learning, by applying human-computer interaction methods to data collection, training, testing, and machine behavior research based on behavioral science methods. To enrich the human-AI interaction experience, I plan to utilize the complementary advantages of human and machine intelligence to process large-scale incomplete and unstructured knowledge information, iterating knowledge to deepen my understanding of data systems. The AI model accepts specific input and determines output according to user feedback information to achieve results better than those achieved separately and avoid the risk of loss of control brought by AI technology. It has been applied in automatic driving, auxiliary medical treatment, video retrieval, and other fields.

---
### **Cooporative AI Glossary Table**

| Glossary | Definition |Source|
| ----------- | ----------- |-----------|
| **Arrow's impossibility theorem** | **Arrow's impossibility theorem** is a related, important, and much earlier result in social choice theory. |[(Narahari 2014)]( https://doi.org/10.1142/9789814525053_0017)|
| **Black Box** | In computing, a **'black box'** is a device, system or program that allows you to see the input and output, but gives no view of the processes and workings between. |[(“The AI Black Box Problem” 2019)]( https://www.thinkautomation.com/bots-and-ai/the-ai-black-box-problem/)|
| **Cooporative AI** | **Cooperative AI** refers to cooporation, communication, and understanding in AI systems consisting of research on AI-AI, AI-human, and AI-facilitated human cooperation. | [(Dafoe et al. 2021)]( https://doi.org/10.1038/d41586-021-01170-0)|
| **Gibbard-Satterthwaite Impossibility Theorem** | **Gibbard-Satterthwaite theorem** shows under some technical conditions that dominant strategy incentive compatibility can only be achieved by dictatorial social choice functions. | [(Narahari 2014)]( https://doi.org/10.1142/9789814525053_0017)|
| **Mechanism** | **Mechanism** refers to a specification of a message space for each individual and an outcome function that maps vectors of messages into social decisions and transfers. | [(Hurwicz 1960)]( https://books.google.com/books/about/Optimality_and_Informational_Efficiency.html?id=p4fwtgAACAAJ ) |
| **Mechanism Design** | **Mechanism design**  shows which mechanisms are optimal for different participants, say sellers or buyers. | [(Harris and Raviv 1981)]( https://doi.org/10.2307/1911413)|





---

### **References:**

Aziz, Haris. 2010. “Multiagent Systems.” ACM SIGACT News 41 (1): 34. https://doi.org/10.1145/1753171.1753181.

Conitzer, Vincent. 2019. “Designing Preferences, Beliefs, and Identities for Artificial Intelligence.” Proceedings of the AAAI Conference on Artificial Intelligence 33 (July): 9755–59. https://doi.org/10.1609/aaai.v33i01.33019755.


Dafoe, Allan, Yoram Bachrach, Gillian Hadfield, Eric Horvitz, Kate Larson, and Thore Graepel. 2021. “Cooperative AI: Machines Must Learn to Find Common Ground.” Nature 593 (7857): 33–36. https://doi.org/10.1038/d41586-021-01170-0.

Dafoe, Allan, Edward Hughes, Yoram Bachrach, Tantum Collins, Kevin Mckee, Joel Leibo, Kate Larson, and Thore Graepel. 2020. “Open Problems in Cooperative AI.” https://arxiv.org/pdf/2012.08630.pdf.

Harris, Milton, and Artur Raviv. 1981. “Allocation Mechanisms and the Design of Auctions.” Econometrica 49 (6): 1477. https://doi.org/10.2307/1911413.

Hurwicz, Leonid. 1960. Optimality and Informational Efficiency in Resource Allocation Processes. Google Books. Stanford University Press. https://books.google.com/books/about/Optimality_and_Informational_Efficiency.html?id=p4fwtgAACAAJ. 

Narahari, Y. 2014. “The Gibbard-Satterthwaite Impossibility Theorem.” Game Theory and Mechanism Design 4 (March): 249–65. https://doi.org/10.1142/9789814525053_0017.

“The AI Black Box Problem.” 2019. ThinkAutomation. November 26, 2019. https://www.thinkautomation.com/bots-and-ai/the-ai-black-box-problem/.

“The Sveriges Riksbank Prize in Economic Sciences in Memory of Alfred Nobel 2007.” 2007. NobelPrize.org. 2007. https://www.nobelprize.org/prizes/economic-sciences/2007/summary/.


